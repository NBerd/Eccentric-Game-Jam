%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!29 &1
OcclusionCullingSettings:
  m_ObjectHideFlags: 0
  serializedVersion: 2
  m_OcclusionBakeSettings:
    smallestOccluder: 5
    smallestHole: 0.25
    backfaceThreshold: 100
  m_SceneGUID: 00000000000000000000000000000000
  m_OcclusionCullingData: {fileID: 0}
--- !u!104 &2
RenderSettings:
  m_ObjectHideFlags: 0
  serializedVersion: 9
  m_Fog: 0
  m_FogColor: {r: 0.5, g: 0.5, b: 0.5, a: 1}
  m_FogMode: 3
  m_FogDensity: 0.01
  m_LinearFogStart: 0
  m_LinearFogEnd: 300
  m_AmbientSkyColor: {r: 0.212, g: 0.227, b: 0.259, a: 1}
  m_AmbientEquatorColor: {r: 0.114, g: 0.125, b: 0.133, a: 1}
  m_AmbientGroundColor: {r: 0.047, g: 0.043, b: 0.035, a: 1}
  m_AmbientIntensity: 1
  m_AmbientMode: 3
  m_SubtractiveShadowColor: {r: 0.42, g: 0.478, b: 0.627, a: 1}
  m_SkyboxMaterial: {fileID: 0}
  m_HaloStrength: 0.5
  m_FlareStrength: 1
  m_FlareFadeSpeed: 3
  m_HaloTexture: {fileID: 0}
  m_SpotCookie: {fileID: 10001, guid: 0000000000000000e000000000000000, type: 0}
  m_DefaultReflectionMode: 0
  m_DefaultReflectionResolution: 128
  m_ReflectionBounces: 1
  m_ReflectionIntensity: 1
  m_CustomReflection: {fileID: 0}
  m_Sun: {fileID: 0}
  m_IndirectSpecularColor: {r: 0, g: 0, b: 0, a: 1}
  m_UseRadianceAmbientProbe: 0
--- !u!157 &3
LightmapSettings:
  m_ObjectHideFlags: 0
  serializedVersion: 12
  m_GIWorkflowMode: 1
  m_GISettings:
    serializedVersion: 2
    m_BounceScale: 1
    m_IndirectOutputScale: 1
    m_AlbedoBoost: 1
    m_EnvironmentLightingMode: 0
    m_EnableBakedLightmaps: 0
    m_EnableRealtimeLightmaps: 0
  m_LightmapEditorSettings:
    serializedVersion: 12
    m_Resolution: 2
    m_BakeResolution: 40
    m_AtlasSize: 1024
    m_AO: 0
    m_AOMaxDistance: 1
    m_CompAOExponent: 1
    m_CompAOExponentDirect: 0
    m_ExtractAmbientOcclusion: 0
    m_Padding: 2
    m_LightmapParameters: {fileID: 0}
    m_LightmapsBakeMode: 1
    m_TextureCompression: 1
    m_FinalGather: 0
    m_FinalGatherFiltering: 1
    m_FinalGatherRayCount: 256
    m_ReflectionCompression: 2
    m_MixedBakeMode: 2
    m_BakeBackend: 0
    m_PVRSampling: 1
    m_PVRDirectSampleCount: 32
    m_PVRSampleCount: 500
    m_PVRBounces: 2
    m_PVREnvironmentSampleCount: 500
    m_PVREnvironmentReferencePointCount: 2048
    m_PVRFilteringMode: 2
    m_PVRDenoiserTypeDirect: 0
    m_PVRDenoiserTypeIndirect: 0
    m_PVRDenoiserTypeAO: 0
    m_PVRFilterTypeDirect: 0
    m_PVRFilterTypeIndirect: 0
    m_PVRFilterTypeAO: 0
    m_PVREnvironmentMIS: 0
    m_PVRCulling: 1
    m_PVRFilteringGaussRadiusDirect: 1
    m_PVRFilteringGaussRadiusIndirect: 5
    m_PVRFilteringGaussRadiusAO: 2
    m_PVRFilteringAtrousPositionSigmaDirect: 0.5
    m_PVRFilteringAtrousPositionSigmaIndirect: 2
    m_PVRFilteringAtrousPositionSigmaAO: 1
    m_ExportTrainingData: 0
    m_TrainingDataDestination: TrainingData
    m_LightProbeSampleCountMultiplier: 4
  m_LightingDataAsset: {fileID: 0}
  m_LightingSettings: {fileID: 0}
--- !u!196 &4
NavMeshSettings:
  serializedVersion: 2
  m_ObjectHideFlags: 0
  m_BuildSettings:
    serializedVersion: 2
    agentTypeID: 0
    agentRadius: 0.5
    agentHeight: 2
    agentSlope: 45
    agentClimb: 0.4
    ledgeDropHeight: 0
    maxJumpAcrossDistance: 0
    minRegionArea: 2
    manualCellSize: 0
    cellSize: 0.16666667
    manualTileSize: 0
    tileSize: 256
    accuratePlacement: 0
    maxJobWorkers: 0
    preserveTilesOutsideBounds: 0
    debug:
      m_Flags: 0
  m_NavMeshData: {fileID: 0}
--- !u!1 &469263115
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 469263116}
  - component: {fileID: 469263118}
  - component: {fileID: 469263117}
  - component: {fileID: 469263119}
  m_Layer: 5
  m_Name: Window
  m_TagString: Untagged
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!224 &469263116
RectTransform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 469263115}
  m_LocalRotation: {x: -0, y: -0, z: -0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: 0}
  m_LocalScale: {x: 1, y: 1, z: 1}
  m_ConstrainProportionsScale: 0
  m_Children:
  - {fileID: 1700137585}
  m_Father: {fileID: 831143112}
  m_RootOrder: 0
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
  m_AnchorMin: {x: 0, y: 0}
  m_AnchorMax: {x: 1, y: 1}
  m_AnchoredPosition: {x: 0, y: 0}
  m_SizeDelta: {x: 0, y: 0}
  m_Pivot: {x: 0.5, y: 0.5}
--- !u!114 &469263117
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 469263115}
  m_Enabled: 0
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 1aa08ab6e0800fa44ae55d278d1423e3, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_Content: {fileID: 1562588491}
  m_Horizontal: 0
  m_Vertical: 1
  m_MovementType: 2
  m_Elasticity: 0.1
  m_Inertia: 0
  m_DecelerationRate: 0.135
  m_ScrollSensitivity: 0
  m_Viewport: {fileID: 1700137585}
  m_HorizontalScrollbar: {fileID: 0}
  m_VerticalScrollbar: {fileID: 0}
  m_HorizontalScrollbarVisibility: 2
  m_VerticalScrollbarVisibility: 2
  m_HorizontalScrollbarSpacing: -3
  m_VerticalScrollbarSpacing: -3
  m_OnValueChanged:
    m_PersistentCalls:
      m_Calls: []
--- !u!222 &469263118
CanvasRenderer:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 469263115}
  m_CullTransparentMesh: 1
--- !u!114 &469263119
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 469263115}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: b56fef87ded67bb4c9be2ac03752bcd2, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  _text: "#include <linux/ioprio.h>\r\n#include <linux/kdev_t.h>\r\n#include \"blk-rq-qos.h\"\r\n\r\nstatic
    DEFINE_MUTEX(blkcg_pol_register_mutex);\r\nstatic DEFINE_MUTEX(blkcg_pol_mutex);\r\n\r\nstruct
    blkcg blkcg_root;\r\nEXPORT_SYMBOL_GPL(blkcg_root);\r\n\r\nstruct cgroup_subsys_state
    * const blkcg_root_css = &blkcg_root.css;\r\nEXPORT_SYMBOL_GPL(blkcg_root_css);\r\n\r\nstatic
    struct blkcg_policy *blkcg_policy[BLKCG_MAX_POLS];\r\n\r\nstatic LIST_HEAD(all_blkcgs);\t\t/*
    protected by blkcg_pol_mutex */\r\n\r\nbool blkcg_debug_stats = false;\r\nstatic
    struct workqueue_struct *blkcg_punt_bio_wq;\r\n\r\n#define BLKG_DESTROY_BATCH_SIZE 
    64\r\n\r\nstatic int init_blkcg_llists(struct blkcg *blkcg)\r\n{\r\n\tint cpu;\r\n\r\n\tblkcg->lhead
    = alloc_percpu_gfp(struct llist_head, GFP_KERNEL);\r\n\tif (!blkcg->lhead)\r\n\t\treturn
    -ENOMEM;\r\n\r\n\tfor_each_possible_cpu(cpu)\r\n\t\tinit_llist_head(per_cpu_ptr(blkcg->lhead,
    cpu));\r\n\treturn 0;\r\n}\r\n\r\nstatic struct cgroup_subsys_state *blkcg_css(void)\r\n{\r\n\tstruct
    cgroup_subsys_state *css;\r\n\r\n\tcss = kthread_blkcg();\r\n\tif (css)\r\n\t\treturn
    css;\r\n\treturn task_css(current, io_cgrp_id);\r\n}\r\n\r\nstatic bool blkcg_policy_enabled(struct
    request_queue *q,\r\n\t\t\t\t const struct blkcg_policy *pol)\r\n{\r\n\treturn
    pol && test_bit(pol->plid, q->blkcg_pols);\r\n}\r\n\r\nstatic void blkg_free_workfn(struct
    work_struct *work)\r\n{\r\n\tstruct blkcg_gq *blkg = container_of(work, struct
    blkcg_gq,\r\n\t\t\t\t\t     free_work);\r\n\tint i;\r\n\r\n\tfor (i = 0; i <
    BLKCG_MAX_POLS; i++)\r\n\t\tif (blkg->pd[i])\r\n\t\t\tblkcg_policy[i]->pd_free_fn(blkg->pd[i]);\r\n\r\n\tif
    (blkg->q)\r\n\t\tblk_put_queue(blkg->q);\r\n\tfree_percpu(blkg->iostat_cpu);\r\n\tpercpu_ref_exit(&blkg->refcnt);\r\n\tkfree(blkg);\r\n}\r\n\r\nstatic
    void blkg_free(struct blkcg_gq *blkg)\r\n{\r\n\tif (!blkg)\r\n\t\treturn;\r\n\r\n\t/*\r\n\t
    * Both ->pd_free_fn() and request queue's release handler may\r\n\t * sleep,
    so free us by scheduling one work func\r\n\t */\r\n\tINIT_WORK(&blkg->free_work,
    blkg_free_workfn);\r\n\tschedule_work(&blkg->free_work);\r\n}\r\n\r\nstatic void
    __blkg_release(struct rcu_head *rcu)\r\n{\r\n\tstruct blkcg_gq *blkg = container_of(rcu,
    struct blkcg_gq, rcu_head);\r\n\r\n\tWARN_ON(!bio_list_empty(&blkg->async_bios));\r\n\r\n\t/*
    release the blkcg and parent blkg refs this blkg has been holding */\r\n\tcss_put(&blkg->blkcg->css);\r\n\tif
    (blkg->parent)\r\n\t\tblkg_put(blkg->parent);\r\n\tblkg_free(blkg);\r\n}\r\n\r\nstatic
    void blkg_release(struct percpu_ref *ref)\r\n{\r\n\tstruct blkcg_gq *blkg = container_of(ref,
    struct blkcg_gq, refcnt);\r\n\r\n\tcall_rcu(&blkg->rcu_head, __blkg_release);\r\n}\r\n\r\nstatic
    void blkg_async_bio_workfn(struct work_struct *work)\r\n{\r\n\tstruct blkcg_gq
    *blkg = container_of(work, struct blkcg_gq,\r\n\t\t\t\t\t     async_bio_work);\r\n\tstruct
    bio_list bios = BIO_EMPTY_LIST;\r\n\tstruct bio *bio;\r\n\tstruct blk_plug plug;\r\n\tbool
    need_plug = false;\r\n\r\n\t/* as long as there are pending bios, @blkg can't
    go away */\r\n\tspin_lock_bh(&blkg->async_bio_lock);\r\n\tbio_list_merge(&bios,
    &blkg->async_bios);\r\n\tbio_list_init(&blkg->async_bios);\r\n\tspin_unlock_bh(&blkg->async_bio_lock);\r\n\r\n\t/*
    start plug only when bio_list contains at least 2 bios */\r\n\tif (bios.head
    && bios.head->bi_next) {\r\n\t\tneed_plug = true;\r\n\t\tblk_start_plug(&plug);\r\n\t}\r\n\twhile
    ((bio = bio_list_pop(&bios)))\r\n\t\tsubmit_bio(bio);\r\n\tif (need_plug)\r\n\t\tblk_finish_plug(&plug);\r\n}\r\n\r\nstruct
    cgroup_subsys_state *bio_blkcg_css(struct bio *bio)\r\n{\r\n\tif (!bio || !bio->bi_blkg)\r\n\t\treturn
    NULL;\r\n\treturn &bio->bi_blkg->blkcg->css;\r\n}\r\nEXPORT_SYMBOL_GPL(bio_blkcg_css);\r\n\r\nstatic
    inline struct blkcg *blkcg_parent(struct blkcg *blkcg)\r\n{\r\n\treturn css_to_blkcg(blkcg->css.parent);\r\n}\r\n\r\nstatic
    struct blkcg_gq *blkg_alloc(struct blkcg *blkcg, struct gendisk *disk,\r\n\t\t\t\t  
    gfp_t gfp_mask)\r\n{\r\n\tstruct blkcg_gq *blkg;\r\n\tint i, cpu;\r\n\r\n\t/*
    alloc and init base part */\r\n\tblkg = kzalloc_node(sizeof(*blkg), gfp_mask,
    disk->queue->node);\r\n\tif (!blkg)\r\n\t\treturn NULL;\r\n\r\n\tif (percpu_ref_init(&blkg->refcnt,
    blkg_release, 0, gfp_mask))\r\n\t\tgoto err_free;\r\n\r\n\tblkg->iostat_cpu =
    alloc_percpu_gfp(struct blkg_iostat_set, gfp_mask);\r\n\tif (!blkg->iostat_cpu)\r\n\t\tgoto
    err_free;\r\n\r\n\tif (!blk_get_queue(disk->queue))\r\n\t\tgoto err_free;\r\n\r\n\tblkg->q
    = disk->queue;\r\n\tINIT_LIST_HEAD(&blkg->q_node);\r\n\tspin_lock_init(&blkg->async_bio_lock);\r\n\tbio_list_init(&blkg->async_bios);\r\n\tINIT_WORK(&blkg->async_bio_work,
    blkg_async_bio_workfn);\r\n\tblkg->blkcg = blkcg;\r\n\r\n\tu64_stats_init(&blkg->iostat.sync);\r\n\tfor_each_possible_cpu(cpu)
    {\r\n\t\tu64_stats_init(&per_cpu_ptr(blkg->iostat_cpu, cpu)->sync);\r\n\t\tper_cpu_ptr(blkg->iostat_cpu,
    cpu)->blkg = blkg;\r\n\t}\r\n\r\n\tfor (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\tstruct
    blkcg_policy *pol = blkcg_policy[i];\r\n\t\tstruct blkg_policy_data *pd;\r\n\r\n\t\tif
    (!blkcg_policy_enabled(disk->queue, pol))\r\n\t\t\tcontinue;\r\n\r\n\t\t/* alloc
    per-policy data and attach it to blkg */\r\n\t\tpd = pol->pd_alloc_fn(gfp_mask,
    disk->queue, blkcg);\r\n\t\tif (!pd)\r\n\t\t\tgoto err_free;\r\n\r\n\t\tblkg->pd[i]
    = pd;\r\n\t\tpd->blkg = blkg;\r\n\t\tpd->plid = i;\r\n\t}\r\n\r\n\treturn blkg;\r\n\r\nerr_free:\r\n\tblkg_free(blkg);\r\n\treturn
    NULL;\r\n}\r\n\r\nstatic struct blkcg_gq *blkg_create(struct blkcg *blkcg, struct
    gendisk *disk,\r\n\t\t\t\t    struct blkcg_gq *new_blkg)\r\n{\r\n\tstruct blkcg_gq
    *blkg;\r\n\tint i, ret;\r\n\r\n\tlockdep_assert_held(&disk->queue->queue_lock);\r\n\r\n\t/*
    request_queue is dying, do not create/recreate a blkg */\r\n\tif (blk_queue_dying(disk->queue))
    {\r\n\t\tret = -ENODEV;\r\n\t\tgoto err_free_blkg;\r\n\t}\r\n\r\n\t/* blkg holds
    a reference to blkcg */\r\n\tif (!css_tryget_online(&blkcg->css)) {\r\n\t\tret
    = -ENODEV;\r\n\t\tgoto err_free_blkg;\r\n\t}\r\n\r\n\t/* allocate */\r\n\tif
    (!new_blkg) {\r\n\t\tnew_blkg = blkg_alloc(blkcg, disk, GFP_NOWAIT | __GFP_NOWARN);\r\n\t\tif
    (unlikely(!new_blkg)) {\r\n\t\t\tret = -ENOMEM;\r\n\t\t\tgoto err_put_css;\r\n\t\t}\r\n\t}\r\n\tblkg
    = new_blkg;\r\n\r\n\t/* link parent */\r\n\tif (blkcg_parent(blkcg)) {\r\n\t\tblkg->parent
    = blkg_lookup(blkcg_parent(blkcg), disk->queue);\r\n\t\tif (WARN_ON_ONCE(!blkg->parent))
    {\r\n\t\t\tret = -ENODEV;\r\n\t\t\tgoto err_put_css;\r\n\t\t}\r\n\t\tblkg_get(blkg->parent);\r\n\t}\r\n\r\n\t/*
    invoke per-policy init */\r\n\tfor (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\tstruct
    blkcg_policy *pol = blkcg_policy[i];\r\n\r\n\t\tif (blkg->pd[i] && pol->pd_init_fn)\r\n\t\t\tpol->pd_init_fn(blkg->pd[i]);\r\n\t}\r\n\r\n\t/*
    insert */\r\n\tspin_lock(&blkcg->lock);\r\n\tret = radix_tree_insert(&blkcg->blkg_tree,
    disk->queue->id, blkg);\r\n\tif (likely(!ret)) {\r\n\t\thlist_add_head_rcu(&blkg->blkcg_node,
    &blkcg->blkg_list);\r\n\t\tlist_add(&blkg->q_node, &disk->queue->blkg_list);\r\n\r\n\t\tfor
    (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\t\tstruct blkcg_policy *pol = blkcg_policy[i];\r\n\r\n\t\t\tif
    (blkg->pd[i] && pol->pd_online_fn)\r\n\t\t\t\tpol->pd_online_fn(blkg->pd[i]);\r\n\t\t}\r\n\t}\r\n\tblkg->online
    = true;\r\n\tspin_unlock(&blkcg->lock);\r\n\r\n\tif (!ret)\r\n\t\treturn blkg;\r\n\r\n\t/*
    @blkg failed fully initialized, use the usual release path */\r\n\tblkg_put(blkg);\r\n\treturn
    ERR_PTR(ret);\r\n\r\nerr_put_css:\r\n\tcss_put(&blkcg->css);\r\nerr_free_blkg:\r\n\tblkg_free(new_blkg);\r\n\treturn
    ERR_PTR(ret);\r\n}\r\n\r\nstatic struct blkcg_gq *blkg_lookup_create(struct blkcg
    *blkcg,\r\n\t\tstruct gendisk *disk)\r\n{\r\n\tstruct request_queue *q = disk->queue;\r\n\tstruct
    blkcg_gq *blkg;\r\n\tunsigned long flags;\r\n\r\n\tWARN_ON_ONCE(!rcu_read_lock_held());\r\n\r\n\tblkg
    = blkg_lookup(blkcg, q);\r\n\tif (blkg)\r\n\t\treturn blkg;\r\n\r\n\tspin_lock_irqsave(&q->queue_lock,
    flags);\r\n\tblkg = blkg_lookup(blkcg, q);\r\n\tif (blkg) {\r\n\t\tif (blkcg
    != &blkcg_root &&\r\n\t\t    blkg != rcu_dereference(blkcg->blkg_hint))\r\n\t\t\trcu_assign_pointer(blkcg->blkg_hint,
    blkg);\r\n\t\tgoto found;\r\n\t}\r\n\r\n\twhile (true) {\r\n\t\tstruct blkcg
    *pos = blkcg;\r\n\t\tstruct blkcg *parent = blkcg_parent(blkcg);\r\n\t\tstruct
    blkcg_gq *ret_blkg = q->root_blkg;\r\n\r\n\t\twhile (parent) {\r\n\t\t\tblkg
    = blkg_lookup(parent, q);\r\n\t\t\tif (blkg) {\r\n\t\t\t\t/* remember closest
    blkg */\r\n\t\t\t\tret_blkg = blkg;\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t\tpos
    = parent;\r\n\t\t\tparent = blkcg_parent(parent);\r\n\t\t}\r\n\r\n\t\tblkg =
    blkg_create(pos, disk, NULL);\r\n\t\tif (IS_ERR(blkg)) {\r\n\t\t\tblkg = ret_blkg;\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\tif
    (pos == blkcg)\r\n\t\t\tbreak;\r\n\t}\r\n\r\nfound:\r\n\tspin_unlock_irqrestore(&q->queue_lock,
    flags);\r\n\treturn blkg;\r\n}\r\n\r\nstatic void blkg_destroy(struct blkcg_gq
    *blkg)\r\n{\r\n\tstruct blkcg *blkcg = blkg->blkcg;\r\n\tint i;\r\n\r\n\tlockdep_assert_held(&blkg->q->queue_lock);\r\n\tlockdep_assert_held(&blkcg->lock);\r\n\r\n\t/*
    Something wrong if we are trying to remove same group twice */\r\n\tWARN_ON_ONCE(list_empty(&blkg->q_node));\r\n\tWARN_ON_ONCE(hlist_unhashed(&blkg->blkcg_node));\r\n\r\n\tfor
    (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\tstruct blkcg_policy *pol = blkcg_policy[i];\r\n\r\n\t\tif
    (blkg->pd[i] && pol->pd_offline_fn)\r\n\t\t\tpol->pd_offline_fn(blkg->pd[i]);\r\n\t}\r\n\r\n\tblkg->online
    = false;\r\n\r\n\tradix_tree_delete(&blkcg->blkg_tree, blkg->q->id);\r\n\tlist_del_init(&blkg->q_node);\r\n\thlist_del_init_rcu(&blkg->blkcg_node);\r\n\r\n\tpercpu_ref_kill(&blkg->refcnt);\r\n}\r\n\r\nstatic
    void blkg_destroy_all(struct gendisk *disk)\r\n{\r\n\tstruct request_queue *q
    = disk->queue;\r\n\tstruct blkcg_gq *blkg, *n;\r\n\tint count = BLKG_DESTROY_BATCH_SIZE;\r\n\r\nrestart:\r\n\tspin_lock_irq(&q->queue_lock);\r\n\tlist_for_each_entry_safe(blkg,
    n, &q->blkg_list, q_node) {\r\n\t\tstruct blkcg *blkcg = blkg->blkcg;\r\n\r\n\t\tspin_lock(&blkcg->lock);\r\n\t\tblkg_destroy(blkg);\r\n\t\tspin_unlock(&blkcg->lock);\r\n\r\n\t\t/*\r\n\t\t
    * in order to avoid holding the spin lock for too long, release\r\n\t\t * it
    when a batch of blkgs are destroyed.\r\n\t\t */\r\n\t\tif (!(--count)) {\r\n\t\t\tcount
    = BLKG_DESTROY_BATCH_SIZE;\r\n\t\t\tspin_unlock_irq(&q->queue_lock);\r\n\t\t\tcond_resched();\r\n\t\t\tgoto
    restart;\r\n\t\t}\r\n\t}\r\n\r\n\tq->root_blkg = NULL;\r\n\tspin_unlock_irq(&q->queue_lock);\r\n}\r\n\r\nstatic
    int blkcg_reset_stats(struct cgroup_subsys_state *css,\r\n\t\t\t     struct cftype
    *cftype, u64 val)\r\n{\r\n\tstruct blkcg *blkcg = css_to_blkcg(css);\r\n\tstruct
    blkcg_gq *blkg;\r\n\tint i, cpu;\r\n\r\n\tmutex_lock(&blkcg_pol_mutex);\r\n\tspin_lock_irq(&blkcg->lock);\r\n\r\n\thlist_for_each_entry(blkg,
    &blkcg->blkg_list, blkcg_node) {\r\n\t\tfor_each_possible_cpu(cpu) {\r\n\t\t\tstruct
    blkg_iostat_set *bis =\r\n\t\t\t\tper_cpu_ptr(blkg->iostat_cpu, cpu);\r\n\t\t\tmemset(bis,
    0, sizeof(*bis));\r\n\t\t}\r\n\t\tmemset(&blkg->iostat, 0, sizeof(blkg->iostat));\r\n\r\n\t\tfor
    (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\t\tstruct blkcg_policy *pol = blkcg_policy[i];\r\n\r\n\t\t\tif
    (blkg->pd[i] && pol->pd_reset_stats_fn)\r\n\t\t\t\tpol->pd_reset_stats_fn(blkg->pd[i]);\r\n\t\t}\r\n\t}\r\n\r\n\tspin_unlock_irq(&blkcg->lock);\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n\treturn
    0;\r\n}\r\n\r\nconst char *blkg_dev_name(struct blkcg_gq *blkg)\r\n{\r\n\tif
    (!blkg->q->disk || !blkg->q->disk->bdi->dev)\r\n\t\treturn NULL;\r\n\treturn
    bdi_dev_name(blkg->q->disk->bdi);\r\n}\r\n\r\n/*\r\n * blkcg_print_blkgs - helper
    for printing per-blkg data\r\n * @sf: seq_file to print to\r\n * @blkcg: blkcg
    of interest\r\n * @prfill: fill function to print out a blkg\r\n * @pol: policy
    in question\r\n * @data: data to be passed to @prfill\r\n * @show_total: to print
    out sum of prfill return values or not\r\n */\r\nvoid blkcg_print_blkgs(struct
    seq_file *sf, struct blkcg *blkcg,\r\n\t\t       u64 (*prfill)(struct seq_file
    *,\r\n\t\t\t\t     struct blkg_policy_data *, int),\r\n\t\t       const struct
    blkcg_policy *pol, int data,\r\n\t\t       bool show_total)\r\n{\r\n\tstruct
    blkcg_gq *blkg;\r\n\tu64 total = 0;\r\n\r\n\trcu_read_lock();\r\n\thlist_for_each_entry_rcu(blkg,
    &blkcg->blkg_list, blkcg_node) {\r\n\t\tspin_lock_irq(&blkg->q->queue_lock);\r\n\t\tif
    (blkcg_policy_enabled(blkg->q, pol))\r\n\t\t\ttotal += prfill(sf, blkg->pd[pol->plid],
    data);\r\n\t\tspin_unlock_irq(&blkg->q->queue_lock);\r\n\t}\r\n\trcu_read_unlock();\r\n\r\n\tif
    (show_total)\r\n\t\tseq_printf(sf, \"Total %llu\\n\", (unsigned long long)total);\r\n}\r\nEXPORT_SYMBOL_GPL(blkcg_print_blkgs);\r\n\r\nu64
    __blkg_prfill_u64(struct seq_file *sf, struct blkg_policy_data *pd, u64 v)\r\n{\r\n\tconst
    char *dname = blkg_dev_name(pd->blkg);\r\n\r\n\tif (!dname)\r\n\t\treturn 0;\r\n\r\n\tseq_printf(sf,
    \"%s %llu\\n\", dname, (unsigned long long)v);\r\n\treturn v;\r\n}\r\nEXPORT_SYMBOL_GPL(__blkg_prfill_u64);\r\n\r\nstruct
    block_device *blkcg_conf_open_bdev(char **inputp)\r\n{\r\n\tchar *input = *inputp;\r\n\tunsigned
    int major, minor;\r\n\tstruct block_device *bdev;\r\n\tint key_len;\r\n\r\n\tif
    (sscanf(input, \"%u:%u%n\", &major, &minor, &key_len) != 2)\r\n\t\treturn ERR_PTR(-EINVAL);\r\n\r\n\tinput
    += key_len;\r\n\tif (!isspace(*input))\r\n\t\treturn ERR_PTR(-EINVAL);\r\n\tinput
    = skip_spaces(input);\r\n\r\n\tbdev = blkdev_get_no_open(MKDEV(major, minor));\r\n\tif
    (!bdev)\r\n\t\treturn ERR_PTR(-ENODEV);\r\n\tif (bdev_is_partition(bdev)) {\r\n\t\tblkdev_put_no_open(bdev);\r\n\t\treturn
    ERR_PTR(-ENODEV);\r\n\t}\r\n\r\n\t*inputp = input;\r\n\treturn bdev;\r\n}\r\n\r\nint
    blkg_conf_prep(struct blkcg *blkcg, const struct blkcg_policy *pol,\r\n\t\t  
    char *input, struct blkg_conf_ctx *ctx)\r\n\t__acquires(rcu) __acquires(&bdev->bd_queue->queue_lock)\r\n{\r\n\tstruct
    block_device *bdev;\r\n\tstruct gendisk *disk;\r\n\tstruct request_queue *q;\r\n\tstruct
    blkcg_gq *blkg;\r\n\tint ret;\r\n\r\n\tbdev = blkcg_conf_open_bdev(&input);\r\n\tif
    (IS_ERR(bdev))\r\n\t\treturn PTR_ERR(bdev);\r\n\tdisk = bdev->bd_disk;\r\n\tq
    = disk->queue;\r\n\r\n\t/*\r\n\t * blkcg_deactivate_policy() requires queue to
    be frozen, we can grab\r\n\t * q_usage_counter to prevent concurrent with blkcg_deactivate_policy().\r\n\t
    */\r\n\tret = blk_queue_enter(q, 0);\r\n\tif (ret)\r\n\t\tgoto fail;\r\n\r\n\trcu_read_lock();\r\n\tspin_lock_irq(&q->queue_lock);\r\n\r\n\tif
    (!blkcg_policy_enabled(q, pol)) {\r\n\t\tret = -EOPNOTSUPP;\r\n\t\tgoto fail_unlock;\r\n\t}\r\n\r\n\tblkg
    = blkg_lookup(blkcg, q);\r\n\tif (blkg)\r\n\t\tgoto success;\r\n\r\n\t/*\r\n\t
    * Create blkgs walking down from blkcg_root to @blkcg, so that all\r\n\t * non-root
    blkgs have access to their parents.\r\n\t */\r\n\twhile (true) {\r\n\t\tstruct
    blkcg *pos = blkcg;\r\n\t\tstruct blkcg *parent;\r\n\t\tstruct blkcg_gq *new_blkg;\r\n\r\n\t\tparent
    = blkcg_parent(blkcg);\r\n\t\twhile (parent && !blkg_lookup(parent, q)) {\r\n\t\t\tpos
    = parent;\r\n\t\t\tparent = blkcg_parent(parent);\r\n\t\t}\r\n\r\n\t\t/* Drop
    locks to do new blkg allocation with GFP_KERNEL. */\r\n\t\tspin_unlock_irq(&q->queue_lock);\r\n\t\trcu_read_unlock();\r\n\r\n\t\tnew_blkg
    = blkg_alloc(pos, disk, GFP_KERNEL);\r\n\t\tif (unlikely(!new_blkg)) {\r\n\t\t\tret
    = -ENOMEM;\r\n\t\t\tgoto fail_exit_queue;\r\n\t\t}\r\n\r\n\t\tif (radix_tree_preload(GFP_KERNEL))
    {\r\n\t\t\tblkg_free(new_blkg);\r\n\t\t\tret = -ENOMEM;\r\n\t\t\tgoto fail_exit_queue;\r\n\t\t}\r\n\r\n\t\trcu_read_lock();\r\n\t\tspin_lock_irq(&q->queue_lock);\r\n\r\n\t\tif
    (!blkcg_policy_enabled(q, pol)) {\r\n\t\t\tblkg_free(new_blkg);\r\n\t\t\tret
    = -EOPNOTSUPP;\r\n\t\t\tgoto fail_preloaded;\r\n\t\t}\r\n\r\n\t\tblkg = blkg_lookup(pos,
    q);\r\n\t\tif (blkg) {\r\n\t\t\tblkg_free(new_blkg);\r\n\t\t} else {\r\n\t\t\tblkg
    = blkg_create(pos, disk, new_blkg);\r\n\t\t\tif (IS_ERR(blkg)) {\r\n\t\t\t\tret
    = PTR_ERR(blkg);\r\n\t\t\t\tgoto fail_preloaded;\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tradix_tree_preload_end();\r\n\r\n\t\tif
    (pos == blkcg)\r\n\t\t\tgoto success;\r\n\t}\r\nsuccess:\r\n\tblk_queue_exit(q);\r\n\tctx->bdev
    = bdev;\r\n\tctx->blkg = blkg;\r\n\tctx->body = input;\r\n\treturn 0;\r\n\r\nfail_preloaded:\r\n\tradix_tree_preload_end();\r\nfail_unlock:\r\n\tspin_unlock_irq(&q->queue_lock);\r\n\trcu_read_unlock();\r\nfail_exit_queue:\r\n\tblk_queue_exit(q);\r\nfail:\r\n\tblkdev_put_no_open(bdev);\r\n\t/*\r\n\t
    * If queue was bypassing, we should retry.  Do so after a\r\n\t * short msleep(). 
    It isn't strictly necessary but queue\r\n\t * can be bypassing for some time
    and it's always nice to\r\n\t * avoid busy looping.\r\n\t */\r\n\tif (ret ==
    -EBUSY) {\r\n\t\tmsleep(10);\r\n\t\tret = restart_syscall();\r\n\t}\r\n\treturn
    ret;\r\n}\r\nEXPORT_SYMBOL_GPL(blkg_conf_prep);\r\n\r\n/**\r\n * blkg_conf_finish
    - finish up per-blkg config update\r\n * @ctx: blkg_conf_ctx initialized by blkg_conf_prep()\r\n*\r\n*
    Finish up after per-blkg config update.  This function must be paired\r\n* with
    blkg_conf_prep().\r\n */\r\nvoid blkg_conf_finish(struct blkg_conf_ctx *ctx)\r\n\t__releases(&ctx->bdev->bd_queue->queue_lock)
    __releases(rcu)\r\n{\r\n\tspin_unlock_irq(&bdev_get_queue(ctx->bdev)->queue_lock);\r\n\trcu_read_unlock();\r\n\tblkdev_put_no_open(ctx->bdev);\r\n}\r\nEXPORT_SYMBOL_GPL(blkg_conf_finish);\r\n\r\nstatic
    void blkg_iostat_set(struct blkg_iostat *dst, struct blkg_iostat *src)\r\n{\r\n\tint
    i;\r\n\r\n\tfor (i = 0; i < BLKG_IOSTAT_NR; i++) {\r\n\t\tdst->bytes[i] = src->bytes[i];\r\n\t\tdst->ios[i]
    = src->ios[i];\r\n\t}\r\n}\r\n\r\nstatic void blkg_iostat_add(struct blkg_iostat
    *dst, struct blkg_iostat *src)\r\n{\r\n\tint i;\r\n\r\n\tfor (i = 0; i < BLKG_IOSTAT_NR;
    i++) {\r\n\t\tdst->bytes[i] += src->bytes[i];\r\n\t\tdst->ios[i] += src->ios[i];\r\n\t}\r\n}\r\n\r\nstatic
    void blkg_iostat_sub(struct blkg_iostat *dst, struct blkg_iostat *src)\r\n{\r\n\tint
    i;\r\n\r\n\tfor (i = 0; i < BLKG_IOSTAT_NR; i++) {\r\n\t\tdst->bytes[i] -= src->bytes[i];\r\n\t\tdst->ios[i]
    -= src->ios[i];\r\n\t}\r\n}\r\n\r\nstatic void blkcg_iostat_update(struct blkcg_gq
    *blkg, struct blkg_iostat *cur,\r\n\t\t\t\tstruct blkg_iostat *last)\r\n{\r\n\tstruct
    blkg_iostat delta;\r\n\tunsigned long flags;\r\n\r\n\t/* propagate percpu delta
    to global */\r\n\tflags = u64_stats_update_begin_irqsave(&blkg->iostat.sync);\r\n\tblkg_iostat_set(&delta,
    cur);\r\n\tblkg_iostat_sub(&delta, last);\r\n\tblkg_iostat_add(&blkg->iostat.cur,
    &delta);\r\n\tblkg_iostat_add(last, &delta);\r\n\tu64_stats_update_end_irqrestore(&blkg->iostat.sync,
    flags);\r\n}\r\n\r\nstatic void blkcg_rstat_flush(struct cgroup_subsys_state
    *css, int cpu)\r\n{\r\n\tstruct blkcg *blkcg = css_to_blkcg(css);\r\n\tstruct
    llist_head *lhead = per_cpu_ptr(blkcg->lhead, cpu);\r\n\tstruct llist_node *lnode;\r\n\tstruct
    blkg_iostat_set *bisc, *next_bisc;\r\n\r\n\t/* Root-level stats are sourced from
    system-wide IO stats */\r\n\tif (!cgroup_parent(css->cgroup))\r\n\t\treturn;\r\n\r\n\trcu_read_lock();\r\n\r\n\tlnode
    = llist_del_all(lhead);\r\n\tif (!lnode)\r\n\t\tgoto out;\r\n\r\n\t/*\r\n\t *
    Iterate only the iostat_cpu's queued in the lockless list.\r\n\t */\r\n\tllist_for_each_entry_safe(bisc,
    next_bisc, lnode, lnode) {\r\n\t\tstruct blkcg_gq *blkg = bisc->blkg;\r\n\t\tstruct
    blkcg_gq *parent = blkg->parent;\r\n\t\tstruct blkg_iostat cur;\r\n\t\tunsigned
    int seq;\r\n\r\n\t\tWRITE_ONCE(bisc->lqueued, false);\r\n\r\n\t\t/* fetch the
    current per-cpu values */\r\n\t\tdo {\r\n\t\t\tseq = u64_stats_fetch_begin(&bisc->sync);\r\n\t\t\tblkg_iostat_set(&cur,
    &bisc->cur);\r\n\t\t} while (u64_stats_fetch_retry(&bisc->sync, seq));\r\n\r\n\t\tblkcg_iostat_update(blkg,
    &cur, &bisc->last);\r\n\r\n\t\t/* propagate global delta to parent (unless that's
    root) */\r\n\t\tif (parent && parent->parent)\r\n\t\t\tblkcg_iostat_update(parent,
    &blkg->iostat.cur,\r\n\t\t\t\t\t    &blkg->iostat.last);\r\n\t\tpercpu_ref_put(&blkg->refcnt);\r\n\t}\r\n\r\nout:\r\n\trcu_read_unlock();\r\n}\r\n\r\nstatic
    void blkcg_fill_root_iostats(void)\r\n{\r\n\tstruct class_dev_iter iter;\r\n\tstruct
    device *dev;\r\n\r\n\tclass_dev_iter_init(&iter, &block_class, NULL, &disk_type);\r\n\twhile
    ((dev = class_dev_iter_next(&iter))) {\r\n\t\tstruct block_device *bdev = dev_to_bdev(dev);\r\n\t\tstruct
    blkcg_gq *blkg = bdev->bd_disk->queue->root_blkg;\r\n\t\tstruct blkg_iostat tmp;\r\n\t\tint
    cpu;\r\n\t\tunsigned long flags;\r\n\r\n\t\tmemset(&tmp, 0, sizeof(tmp));\r\n\t\tfor_each_possible_cpu(cpu)
    {\r\n\t\t\tstruct disk_stats *cpu_dkstats;\r\n\r\n\t\t\tcpu_dkstats = per_cpu_ptr(bdev->bd_stats,
    cpu);\r\n\t\t\ttmp.ios[BLKG_IOSTAT_READ] +=\r\n\t\t\t\tcpu_dkstats->ios[STAT_READ];\r\n\t\t\ttmp.ios[BLKG_IOSTAT_WRITE]
    +=\r\n\t\t\t\tcpu_dkstats->ios[STAT_WRITE];\r\n\t\t\ttmp.ios[BLKG_IOSTAT_DISCARD]
    +=\r\n\t\t\t\tcpu_dkstats->ios[STAT_DISCARD];\r\n\t\t\t// convert sectors to
    bytes\r\n\t\t\ttmp.bytes[BLKG_IOSTAT_READ] +=\r\n\t\t\t\tcpu_dkstats->sectors[STAT_READ]
    << 9;\r\n\t\t\ttmp.bytes[BLKG_IOSTAT_WRITE] +=\r\n\t\t\t\tcpu_dkstats->sectors[STAT_WRITE]
    << 9;\r\n\t\t\ttmp.bytes[BLKG_IOSTAT_DISCARD] +=\r\n\t\t\t\tcpu_dkstats->sectors[STAT_DISCARD]
    << 9;\r\n\t\t}\r\n\r\n\t\tflags = u64_stats_update_begin_irqsave(&blkg->iostat.sync);\r\n\t\tblkg_iostat_set(&blkg->iostat.cur,
    &tmp);\r\n\t\tu64_stats_update_end_irqrestore(&blkg->iostat.sync, flags);\r\n\t}\r\n}\r\n\r\nstatic
    void blkcg_print_one_stat(struct blkcg_gq *blkg, struct seq_file *s)\r\n{\r\n\tstruct
    blkg_iostat_set *bis = &blkg->iostat;\r\n\tu64 rbytes, wbytes, rios, wios, dbytes,
    dios;\r\n\tconst char *dname;\r\n\tunsigned seq;\r\n\tint i;\r\n\r\n\tif (!blkg->online)\r\n\t\treturn;\r\n\r\n\tdname
    = blkg_dev_name(blkg);\r\n\tif (!dname)\r\n\t\treturn;\r\n\r\n\tseq_printf(s,
    \"%s \", dname);\r\n\r\n\tdo {\r\n\t\tseq = u64_stats_fetch_begin(&bis->sync);\r\n\r\n\t\trbytes
    = bis->cur.bytes[BLKG_IOSTAT_READ];\r\n\t\twbytes = bis->cur.bytes[BLKG_IOSTAT_WRITE];\r\n\t\tdbytes
    = bis->cur.bytes[BLKG_IOSTAT_DISCARD];\r\n\t\trios = bis->cur.ios[BLKG_IOSTAT_READ];\r\n\t\twios
    = bis->cur.ios[BLKG_IOSTAT_WRITE];\r\n\t\tdios = bis->cur.ios[BLKG_IOSTAT_DISCARD];\r\n\t}
    while (u64_stats_fetch_retry(&bis->sync, seq));\r\n\r\n\tif (rbytes || wbytes
    || rios || wios) {\r\n\t\tseq_printf(s, \"rbytes=%llu wbytes=%llu rios=%llu wios=%llu
    dbytes=%llu dios=%llu\",\r\n\t\t\trbytes, wbytes, rios, wios,\r\n\t\t\tdbytes,
    dios);\r\n\t}\r\n\r\n\tif (blkcg_debug_stats && atomic_read(&blkg->use_delay))
    {\r\n\t\tseq_printf(s, \" use_delay=%d delay_nsec=%llu\",\r\n\t\t\tatomic_read(&blkg->use_delay),\r\n\t\t\tatomic64_read(&blkg->delay_nsec));\r\n\t}\r\n\r\n\tfor
    (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\tstruct blkcg_policy *pol = blkcg_policy[i];\r\n\r\n\t\tif
    (!blkg->pd[i] || !pol->pd_stat_fn)\r\n\t\t\tcontinue;\r\n\r\n\t\tpol->pd_stat_fn(blkg->pd[i],
    s);\r\n\t}\r\n\r\n\tseq_puts(s, \"\\n\");\r\n}\r\n\r\nstatic int blkcg_print_stat(struct
    seq_file *sf, void *v)\r\n{\r\n\tstruct blkcg *blkcg = css_to_blkcg(seq_css(sf));\r\n\tstruct
    blkcg_gq *blkg;\r\n\r\n\tif (!seq_css(sf)->parent)\r\n\t\tblkcg_fill_root_iostats();\r\n\telse\r\n\t\tcgroup_rstat_flush(blkcg->css.cgroup);\r\n\r\n\trcu_read_lock();\r\n\thlist_for_each_entry_rcu(blkg,
    &blkcg->blkg_list, blkcg_node) {\r\n\t\tspin_lock_irq(&blkg->q->queue_lock);\r\n\t\tblkcg_print_one_stat(blkg,
    sf);\r\n\t\tspin_unlock_irq(&blkg->q->queue_lock);\r\n\t}\r\n\trcu_read_unlock();\r\n\treturn
    0;\r\n}\r\n\r\nstatic struct cftype blkcg_files[] = {\r\n\t{\r\n\t\t.name = \"stat\",\r\n\t\t.seq_show
    = blkcg_print_stat,\r\n\t},\r\n\t{ }\t/* terminate */\r\n};\r\n\r\nstatic struct
    cftype blkcg_legacy_files[] = {\r\n\t{\r\n\t\t.name = \"reset_stats\",\r\n\t\t.write_u64
    = blkcg_reset_stats,\r\n\t},\r\n\t{ }\t/* terminate */\r\n};\r\n\r\n#ifdef CONFIG_CGROUP_WRITEBACK\r\nstruct
    list_head *blkcg_get_cgwb_list(struct cgroup_subsys_state *css)\r\n{\r\n\treturn
    &css_to_blkcg(css)->cgwb_list;\r\n}\r\n#endif\r\n\r\nstatic void blkcg_destroy_blkgs(struct
    blkcg *blkcg)\r\n{\r\n\tmight_sleep();\r\n\r\n\tspin_lock_irq(&blkcg->lock);\r\n\r\n\twhile
    (!hlist_empty(&blkcg->blkg_list)) {\r\n\t\tstruct blkcg_gq *blkg = hlist_entry(blkcg->blkg_list.first,\r\n\t\t\t\t\t\tstruct
    blkcg_gq, blkcg_node);\r\n\t\tstruct request_queue *q = blkg->q;\r\n\r\n\t\tif
    (need_resched() || !spin_trylock(&q->queue_lock)) {\r\n\t\t\t/*\r\n\t\t\t * Given
    that the system can accumulate a huge number\r\n\t\t\t * of blkgs in pathological
    cases, check to see if we\r\n\t\t\t * need to rescheduling to avoid softlockup.\r\n\t\t\t
    */\r\n\t\t\tspin_unlock_irq(&blkcg->lock);\r\n\t\t\tcond_resched();\r\n\t\t\tspin_lock_irq(&blkcg->lock);\r\n\t\t\tcontinue;\r\n\t\t}\r\n\r\n\t\tblkg_destroy(blkg);\r\n\t\tspin_unlock(&q->queue_lock);\r\n\t}\r\n\r\n\tspin_unlock_irq(&blkcg->lock);\r\n}\r\n\r\nvoid
    blkcg_unpin_online(struct cgroup_subsys_state *blkcg_css)\r\n{\r\n\tstruct blkcg
    *blkcg = css_to_blkcg(blkcg_css);\r\n\r\n\tdo {\r\n\t\tif (!refcount_dec_and_test(&blkcg->online_pin))\r\n\t\t\tbreak;\r\n\t\tblkcg_destroy_blkgs(blkcg);\r\n\t\tblkcg
    = blkcg_parent(blkcg);\r\n\t} while (blkcg);\r\n}\r\n\r\nstatic void blkcg_css_offline(struct
    cgroup_subsys_state *css)\r\n{\r\n\t/* this prevents anyone from attaching or
    migrating to this blkcg */\r\n\twb_blkcg_offline(css);\r\n\r\n\t/* put the base
    online pin allowing step 2 to be triggered */\r\n\tblkcg_unpin_online(css);\r\n}\r\n\r\nstatic
    void blkcg_css_free(struct cgroup_subsys_state *css)\r\n{\r\n\tstruct blkcg *blkcg
    = css_to_blkcg(css);\r\n\tint i;\r\n\r\n\tmutex_lock(&blkcg_pol_mutex);\r\n\r\n\tlist_del(&blkcg->all_blkcgs_node);\r\n\r\n\tfor
    (i = 0; i < BLKCG_MAX_POLS; i++)\r\n\t\tif (blkcg->cpd[i])\r\n\t\t\tblkcg_policy[i]->cpd_free_fn(blkcg->cpd[i]);\r\n\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n\r\n\tfree_percpu(blkcg->lhead);\r\n\tkfree(blkcg);\r\n}\r\n\r\nstatic
    struct cgroup_subsys_state *\r\nblkcg_css_alloc(struct cgroup_subsys_state *parent_css)\r\n{\r\n\tstruct
    blkcg *blkcg;\r\n\tint i;\r\n\r\n\tmutex_lock(&blkcg_pol_mutex);\r\n\r\n\tif
    (!parent_css) {\r\n\t\tblkcg = &blkcg_root;\r\n\t} else {\r\n\t\tblkcg = kzalloc(sizeof(*blkcg),
    GFP_KERNEL);\r\n\t\tif (!blkcg)\r\n\t\t\tgoto unlock;\r\n\t}\r\n\r\n\tif (init_blkcg_llists(blkcg))\r\n\t\tgoto
    free_blkcg;\r\n\r\n\tfor (i = 0; i < BLKCG_MAX_POLS ; i++) {\r\n\t\tstruct blkcg_policy
    *pol = blkcg_policy[i];\r\n\t\tstruct blkcg_policy_data *cpd;\r\n\r\n\t\tif (!pol
    || !pol->cpd_alloc_fn)\r\n\t\t\tcontinue;\r\n\r\n\t\tcpd = pol->cpd_alloc_fn(GFP_KERNEL);\r\n\t\tif
    (!cpd)\r\n\t\t\tgoto free_pd_blkcg;\r\n\r\n\t\tblkcg->cpd[i] = cpd;\r\n\t\tcpd->blkcg
    = blkcg;\r\n\t\tcpd->plid = i;\r\n\t\tif (pol->cpd_init_fn)\r\n\t\t\tpol->cpd_init_fn(cpd);\r\n\t}\r\n\r\n\tspin_lock_init(&blkcg->lock);\r\n\trefcount_set(&blkcg->online_pin,
    1);\r\n\tINIT_RADIX_TREE(&blkcg->blkg_tree, GFP_NOWAIT | __GFP_NOWARN);\r\n\tINIT_HLIST_HEAD(&blkcg->blkg_list);\r\n#ifdef
    CONFIG_CGROUP_WRITEBACK\r\n\tINIT_LIST_HEAD(&blkcg->cgwb_list);\r\n#endif\r\n\tlist_add_tail(&blkcg->all_blkcgs_node,
    &all_blkcgs);\r\n\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n\treturn &blkcg->css;\r\n\r\nfree_pd_blkcg:\r\n\tfor
    (i--; i >= 0; i--)\r\n\t\tif (blkcg->cpd[i])\r\n\t\t\tblkcg_policy[i]->cpd_free_fn(blkcg->cpd[i]);\r\n\tfree_percpu(blkcg->lhead);\r\nfree_blkcg:\r\n\tif
    (blkcg != &blkcg_root)\r\n\t\tkfree(blkcg);\r\nunlock:\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n\treturn
    ERR_PTR(-ENOMEM);\r\n}\r\n\r\nstatic int blkcg_css_online(struct cgroup_subsys_state
    *css)\r\n{\r\n\tstruct blkcg *parent = blkcg_parent(css_to_blkcg(css));\r\n\r\n\t/*\r\n\t
    * blkcg_pin_online() is used to delay blkcg offline so that blkgs\r\n\t * don't
    go offline while cgwbs are still active on them.  Pin the\r\n\t * parent so that
    offline always happens towards the root.\r\n\t */\r\n\tif (parent)\r\n\t\tblkcg_pin_online(&parent->css);\r\n\treturn
    0;\r\n}\r\n\r\nint blkcg_init_disk(struct gendisk *disk)\r\n{\r\n\tstruct request_queue
    *q = disk->queue;\r\n\tstruct blkcg_gq *new_blkg, *blkg;\r\n\tbool preloaded;\r\n\tint
    ret;\r\n\r\n\tINIT_LIST_HEAD(&q->blkg_list);\r\n\r\n\tnew_blkg = blkg_alloc(&blkcg_root,
    disk, GFP_KERNEL);\r\n\tif (!new_blkg)\r\n\t\treturn -ENOMEM;\r\n\r\n\tpreloaded
    = !radix_tree_preload(GFP_KERNEL);\r\n\r\n\t/* Make sure the root blkg exists.
    */\r\n\t/* spin_lock_irq can serve as RCU read-side critical section. */\r\n\tspin_lock_irq(&q->queue_lock);\r\n\tblkg
    = blkg_create(&blkcg_root, disk, new_blkg);\r\n\tif (IS_ERR(blkg))\r\n\t\tgoto
    err_unlock;\r\n\tq->root_blkg = blkg;\r\n\tspin_unlock_irq(&q->queue_lock);\r\n\r\n\tif
    (preloaded)\r\n\t\tradix_tree_preload_end();\r\n\r\n\tret = blk_ioprio_init(disk);\r\n\tif
    (ret)\r\n\t\tgoto err_destroy_all;\r\n\r\n\tret = blk_throtl_init(disk);\r\n\tif
    (ret)\r\n\t\tgoto err_ioprio_exit;\r\n\r\n\tret = blk_iolatency_init(disk);\r\n\tif
    (ret)\r\n\t\tgoto err_throtl_exit;\r\n\r\n\treturn 0;\r\n\r\nerr_throtl_exit:\r\n\tblk_throtl_exit(disk);\r\nerr_ioprio_exit:\r\n\tblk_ioprio_exit(disk);\r\nerr_destroy_all:\r\n\tblkg_destroy_all(disk);\r\n\treturn
    ret;\r\nerr_unlock:\r\n\tspin_unlock_irq(&q->queue_lock);\r\n\tif (preloaded)\r\n\t\tradix_tree_preload_end();\r\n\treturn
    PTR_ERR(blkg);\r\n}\r\n\r\nvoid blkcg_exit_disk(struct gendisk *disk)\r\n{\r\n\tblkg_destroy_all(disk);\r\n\trq_qos_exit(disk->queue);\r\n\tblk_throtl_exit(disk);\r\n}\r\n\r\nstatic
    void blkcg_bind(struct cgroup_subsys_state *root_css)\r\n{\r\n\tint i;\r\n\r\n\tmutex_lock(&blkcg_pol_mutex);\r\n\r\n\tfor
    (i = 0; i < BLKCG_MAX_POLS; i++) {\r\n\t\tstruct blkcg_policy *pol = blkcg_policy[i];\r\n\t\tstruct
    blkcg *blkcg;\r\n\r\n\t\tif (!pol || !pol->cpd_bind_fn)\r\n\t\t\tcontinue;\r\n\r\n\t\tlist_for_each_entry(blkcg,
    &all_blkcgs, all_blkcgs_node)\r\n\t\t\tif (blkcg->cpd[pol->plid])\r\n\t\t\t\tpol->cpd_bind_fn(blkcg->cpd[pol->plid]);\r\n\t}\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n}\r\n\r\nstatic
    void blkcg_exit(struct task_struct *tsk)\r\n{\r\n\tif (tsk->throttle_queue)\r\n\t\tblk_put_queue(tsk->throttle_queue);\r\n\ttsk->throttle_queue
    = NULL;\r\n}\r\n\r\nstruct cgroup_subsys io_cgrp_subsys = {\r\n\t.css_alloc =
    blkcg_css_alloc,\r\n\t.css_online = blkcg_css_online,\r\n\t.css_offline = blkcg_css_offline,\r\n\t.css_free
    = blkcg_css_free,\r\n\t.css_rstat_flush = blkcg_rstat_flush,\r\n\t.bind = blkcg_bind,\r\n\t.dfl_cftypes
    = blkcg_files,\r\n\t.legacy_cftypes = blkcg_legacy_files,\r\n\t.legacy_name =
    \"blkio\",\r\n\t.exit = blkcg_exit,\r\n#ifdef CONFIG_MEMCG\r\n\t/*\r\n\t * This
    ensures that, if available, memcg is automatically enabled\r\n\t * together on
    the default hierarchy so that the owner cgroup can\r\n\t * be retrieved from
    writeback pages.\r\n\t */\r\n\t.depends_on = 1 << memory_cgrp_id,\r\n#endif\r\n};\r\nEXPORT_SYMBOL_GPL(io_cgrp_subsys);\r\n\r\nint
    blkcg_activate_policy(struct request_queue *q,\r\n\t\t\t  const struct blkcg_policy
    *pol)\r\n{\r\n\tstruct blkg_policy_data *pd_prealloc = NULL;\r\n\tstruct blkcg_gq
    *blkg, *pinned_blkg = NULL;\r\n\tint ret;\r\n\r\n\tif (blkcg_policy_enabled(q,
    pol))\r\n\t\treturn 0;\r\n\r\n\tif (queue_is_mq(q))\r\n\t\tblk_mq_freeze_queue(q);\r\nretry:\r\n\tspin_lock_irq(&q->queue_lock);\r\n\r\n\t/*
    blkg_list is pushed at the head, reverse walk to allocate parents first */\r\n\tlist_for_each_entry_reverse(blkg,
    &q->blkg_list, q_node) {\r\n\t\tstruct blkg_policy_data *pd;\r\n\r\n\t\tif (blkg->pd[pol->plid])\r\n\t\t\tcontinue;\r\n\r\n\t\t/*
    If prealloc matches, use it; otherwise try GFP_NOWAIT */\r\n\t\tif (blkg == pinned_blkg)
    {\r\n\t\t\tpd = pd_prealloc;\r\n\t\t\tpd_prealloc = NULL;\r\n\t\t} else {\r\n\t\t\tpd
    = pol->pd_alloc_fn(GFP_NOWAIT | __GFP_NOWARN, q,\r\n\t\t\t\t\t      blkg->blkcg);\r\n\t\t}\r\n\r\n\t\tif
    (!pd) {\r\n\t\t\t/*\r\n\t\t\t * GFP_NOWAIT failed.  Free the existing one and\r\n\t\t\t
    * prealloc for @blkg w/ GFP_KERNEL.\r\n\t\t\t */\r\n\t\t\tif (pinned_blkg)\r\n\t\t\t\tblkg_put(pinned_blkg);\r\n\t\t\tblkg_get(blkg);\r\n\t\t\tpinned_blkg
    = blkg;\r\n\r\n\t\t\tspin_unlock_irq(&q->queue_lock);\r\n\r\n\t\t\tif (pd_prealloc)\r\n\t\t\t\tpol->pd_free_fn(pd_prealloc);\r\n\t\t\tpd_prealloc
    = pol->pd_alloc_fn(GFP_KERNEL, q,\r\n\t\t\t\t\t\t       blkg->blkcg);\r\n\t\t\tif
    (pd_prealloc)\r\n\t\t\t\tgoto retry;\r\n\t\t\telse\r\n\t\t\t\tgoto enomem;\r\n\t\t}\r\n\r\n\t\tblkg->pd[pol->plid]
    = pd;\r\n\t\tpd->blkg = blkg;\r\n\t\tpd->plid = pol->plid;\r\n\t}\r\n\r\n\t/*
    all allocated, init in the same order */\r\n\tif (pol->pd_init_fn)\r\n\t\tlist_for_each_entry_reverse(blkg,
    &q->blkg_list, q_node)\r\n\t\t\tpol->pd_init_fn(blkg->pd[pol->plid]);\r\n\r\n\t__set_bit(pol->plid,
    q->blkcg_pols);\r\n\tret = 0;\r\n\r\n\tspin_unlock_irq(&q->queue_lock);\r\nout:\r\n\tif
    (queue_is_mq(q))\r\n\t\tblk_mq_unfreeze_queue(q);\r\n\tif (pinned_blkg)\r\n\t\tblkg_put(pinned_blkg);\r\n\tif
    (pd_prealloc)\r\n\t\tpol->pd_free_fn(pd_prealloc);\r\n\treturn ret;\r\n\r\nenomem:\r\n\t/*
    alloc failed, nothing's initialized yet, free everything */\r\n\tspin_lock_irq(&q->queue_lock);\r\n\tlist_for_each_entry(blkg,
    &q->blkg_list, q_node) {\r\n\t\tstruct blkcg *blkcg = blkg->blkcg;\r\n\r\n\t\tspin_lock(&blkcg->lock);\r\n\t\tif
    (blkg->pd[pol->plid]) {\r\n\t\t\tpol->pd_free_fn(blkg->pd[pol->plid]);\r\n\t\t\tblkg->pd[pol->plid]
    = NULL;\r\n\t\t}\r\n\t\tspin_unlock(&blkcg->lock);\r\n\t}\r\n\tspin_unlock_irq(&q->queue_lock);\r\n\tret
    = -ENOMEM;\r\n\tgoto out;\r\n}\r\nEXPORT_SYMBOL_GPL(blkcg_activate_policy);\r\n\r\n/**\r\n*
    blkcg_deactivate_policy - deactivate a blkcg policy on a request_queue\r\n* @q:
    request_queue of interest\r\n * @pol: blkcg policy to deactivate\r\n *\r\n* Deactivate
    @pol on @q.  Follows the same synchronization rules as\r\n * blkcg_activate_policy().\r\n*/\r\nvoid
    blkcg_deactivate_policy(struct request_queue *q,\r\n\t\t\t     const struct blkcg_policy
    *pol)\r\n{\r\n\tstruct blkcg_gq *blkg;\r\n\r\n\tif (!blkcg_policy_enabled(q,
    pol))\r\n\t\treturn;\r\n\r\n\tif (queue_is_mq(q))\r\n\t\tblk_mq_freeze_queue(q);\r\n\r\n\tspin_lock_irq(&q->queue_lock);\r\n\r\n\t__clear_bit(pol->plid,
    q->blkcg_pols);\r\n\r\n\tlist_for_each_entry(blkg, &q->blkg_list, q_node) {\r\n\t\tstruct
    blkcg *blkcg = blkg->blkcg;\r\n\r\n\t\tspin_lock(&blkcg->lock);\r\n\t\tif (blkg->pd[pol->plid])
    {\r\n\t\t\tif (pol->pd_offline_fn)\r\n\t\t\t\tpol->pd_offline_fn(blkg->pd[pol->plid]);\r\n\t\t\tpol->pd_free_fn(blkg->pd[pol->plid]);\r\n\t\t\tblkg->pd[pol->plid]
    = NULL;\r\n\t\t}\r\n\t\tspin_unlock(&blkcg->lock);\r\n\t}\r\n\r\n\tspin_unlock_irq(&q->queue_lock);\r\n\r\n\tif
    (queue_is_mq(q))\r\n\t\tblk_mq_unfreeze_queue(q);\r\n}\r\nEXPORT_SYMBOL_GPL(blkcg_deactivate_policy);\r\n\r\nstatic
    void blkcg_free_all_cpd(struct blkcg_policy *pol)\r\n{\r\n\tstruct blkcg *blkcg;\r\n\r\n\tlist_for_each_entry(blkcg,
    &all_blkcgs, all_blkcgs_node) {\r\n\t\tif (blkcg->cpd[pol->plid]) {\r\n\t\t\tpol->cpd_free_fn(blkcg->cpd[pol->plid]);\r\n\t\t\tblkcg->cpd[pol->plid]
    = NULL;\r\n\t\t}\r\n\t}\r\n}\r\n\r\n/**\r\n * blkcg_policy_register - register
    a blkcg policy\r\n * @pol: blkcg policy to register\r\n *\r\n * Register @pol
    with blkcg core.  Might sleep and @pol may be modified on\r\n * successful registration. 
    Returns 0 on success and -errno on failure.\r\n */\r\nint blkcg_policy_register(struct
    blkcg_policy *pol)\r\n{\r\n\tstruct blkcg *blkcg;\r\n\tint i, ret;\r\n\r\n\tmutex_lock(&blkcg_pol_register_mutex);\r\n\tmutex_lock(&blkcg_pol_mutex);\r\n\r\n\t/*
    find an empty slot */\r\n\tret = -ENOSPC;\r\n\tfor (i = 0; i < BLKCG_MAX_POLS;
    i++)\r\n\t\tif (!blkcg_policy[i])\r\n\t\t\tbreak;\r\n\tif (i >= BLKCG_MAX_POLS)
    {\r\n\t\tpr_warn(\"blkcg_policy_register: BLKCG_MAX_POLS too small\\n\");\r\n\t\tgoto
    err_unlock;\r\n\t}\r\n\r\n\t/* Make sure cpd/pd_alloc_fn and cpd/pd_free_fn in
    pairs */\r\n\tif ((!pol->cpd_alloc_fn ^ !pol->cpd_free_fn) ||\r\n\t\t(!pol->pd_alloc_fn
    ^ !pol->pd_free_fn))\r\n\t\tgoto err_unlock;\r\n\r\n\t/* register @pol */\r\n\tpol->plid
    = i;\r\n\tblkcg_policy[pol->plid] = pol;\r\n\r\n\t/* allocate and install cpd's
    */\r\n\tif (pol->cpd_alloc_fn) {\r\n\t\tlist_for_each_entry(blkcg, &all_blkcgs,
    all_blkcgs_node) {\r\n\t\t\tstruct blkcg_policy_data *cpd;\r\n\r\n\t\t\tcpd =
    pol->cpd_alloc_fn(GFP_KERNEL);\r\n\t\t\tif (!cpd)\r\n\t\t\t\tgoto err_free_cpds;\r\n\r\n\t\t\tblkcg->cpd[pol->plid]
    = cpd;\r\n\t\t\tcpd->blkcg = blkcg;\r\n\t\t\tcpd->plid = pol->plid;\r\n\t\t\tif
    (pol->cpd_init_fn)\r\n\t\t\t\tpol->cpd_init_fn(cpd);\r\n\t\t}\r\n\t}\r\n\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n\r\n\t/*
    everything is in place, add intf files for the new policy */\r\n\tif (pol->dfl_cftypes)\r\n\t\tWARN_ON(cgroup_add_dfl_cftypes(&io_cgrp_subsys,\r\n\t\t\t\t\t      
    pol->dfl_cftypes));\r\n\tif (pol->legacy_cftypes)\r\n\t\tWARN_ON(cgroup_add_legacy_cftypes(&io_cgrp_subsys,\r\n\t\t\t\t\t\t 
    pol->legacy_cftypes));\r\n\tmutex_unlock(&blkcg_pol_register_mutex);\r\n\treturn
    0;\r\n\r\nerr_free_cpds:\r\n\tif (pol->cpd_free_fn)\r\n\t\tblkcg_free_all_cpd(pol);\r\n\r\n\tblkcg_policy[pol->plid]
    = NULL;\r\nerr_unlock:\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\n\tmutex_unlock(&blkcg_pol_register_mutex);\r\n\treturn
    ret;\r\n}\r\nEXPORT_SYMBOL_GPL(blkcg_policy_register);\r\n\r\n/**\r\n * blkcg_policy_unregister
    - unregister a blkcg policy\r\n * @pol: blkcg policy to unregister\r\n *\r\n*
    Undo blkcg_policy_register(@pol).  Might sleep.\r\n */\r\nvoid blkcg_policy_unregister(struct
    blkcg_policy *pol)\r\n{\r\n\tmutex_lock(&blkcg_pol_register_mutex);\r\n\r\n\tif
    (WARN_ON(blkcg_policy[pol->plid] != pol))\r\n\t\tgoto out_unlock;\r\n\r\n\t/*
    kill the intf files first */\r\n\tif (pol->dfl_cftypes)\r\n\t\tcgroup_rm_cftypes(pol->dfl_cftypes);\r\n\tif
    (pol->legacy_cftypes)\r\n\t\tcgroup_rm_cftypes(pol->legacy_cftypes);\r\n\r\n\t/*
    remove cpds and unregister */\r\n\tmutex_lock(&blkcg_pol_mutex);\r\n\r\n\tif
    (pol->cpd_free_fn)\r\n\t\tblkcg_free_all_cpd(pol);\r\n\r\n\tblkcg_policy[pol->plid]
    = NULL;\r\n\r\n\tmutex_unlock(&blkcg_pol_mutex);\r\nout_unlock:\r\n\tmutex_unlock(&blkcg_pol_register_mutex);\r\n}\r\nEXPORT_SYMBOL_GPL(blkcg_policy_unregister);\r\n\r\nbool
    __blkcg_punt_bio_submit(struct bio *bio)\r\n{\r\n\tstruct blkcg_gq *blkg = bio->bi_blkg;\r\n\r\n\t/*
    consume the flag first */\r\n\tbio->bi_opf &= ~REQ_CGROUP_PUNT;\r\n\r\n\t/* never
    bounce for the root cgroup */\r\n\tif (!blkg->parent)\r\n\t\treturn false;\r\n\r\n\tspin_lock_bh(&blkg->async_bio_lock);\r\n\tbio_list_add(&blkg->async_bios,
    bio);\r\n\tspin_unlock_bh(&blkg->async_bio_lock);\r\n\r\n\tqueue_work(blkcg_punt_bio_wq,
    &blkg->async_bio_work);\r\n\treturn true;\r\n}\r\n\r\n/*\r\n * Scale the accumulated
    delay based on how long it has been since we updated\r\n * the delay.  We only
    call this when we are adding delay, in case it's been a\r\n * while since we
    added delay, and when we are checking to see if we need to\r\n * delay a task,
    to account for any delays that may have occurred.\r\n */\r\nstatic void blkcg_scale_delay(struct
    blkcg_gq *blkg, u64 now)\r\n{\r\n\tu64 old = atomic64_read(&blkg->delay_start);\r\n\r\n\t/*
    negative use_delay means no scaling, see blkcg_set_delay() */\r\n\tif (atomic_read(&blkg->use_delay)
    < 0)\r\n\t\treturn;\r\n\r\n\t/*\r\n\t * We only want to scale down every second. 
    The idea here is that we\r\n\t * want to delay people for min(delay_nsec, NSEC_PER_SEC)
    in a certain\r\n\t * time window.  We only want to throttle tasks for recent
    delay that\r\n\t * has occurred, in 1 second time windows since that's the maximum\r\n\t
    * things can be throttled.  We save the current delay window in\r\n\t * blkg->last_delay
    so we know what amount is still left to be charged\r\n\t * to the blkg from this
    point onward.  blkg->last_use keeps track of\r\n\t * the use_delay counter. 
    The idea is if we're unthrottling the blkg we\r\n\t * are ok with whatever is
    happening now, and we can take away more of\r\n\t * the accumulated delay as
    we've already throttled enough that\r\n\t * everybody is happy with their IO
    latencies.\r\n\t */\r\n\tif (time_before64(old + NSEC_PER_SEC, now) &&\r\n\t   
    atomic64_try_cmpxchg(&blkg->delay_start, &old, now)) {\r\n\t\tu64 cur = atomic64_read(&blkg->delay_nsec);\r\n\t\tu64
    sub = min_t(u64, blkg->last_delay, now - old);\r\n\t\tint cur_use = atomic_read(&blkg->use_delay);\r\n\r\n\t\t/*\r\n\t\t
    * We've been unthrottled, subtract a larger chunk of our\r\n\t\t * accumulated
    delay.\r\n\t\t */\r\n\t\tif (cur_use < blkg->last_use)\r\n\t\t\tsub = max_t(u64,
    sub, blkg->last_delay >> 1);\r\n\r\n\t\t/*\r\n\t\t * This shouldn't happen, but
    handle it anyway.  Our delay_nsec\r\n\t\t * should only ever be growing except
    here where we subtract out\r\n\t\t * min(last_delay, 1 second), but lord knows
    bugs happen and I'd\r\n\t\t * rather not end up with negative numbers.\r\n\t\t
    */\r\n\t\tif (unlikely(cur < sub)) {\r\n\t\t\tatomic64_set(&blkg->delay_nsec,
    0);\r\n\t\t\tblkg->last_delay = 0;\r\n\t\t} else {\r\n\t\t\tatomic64_sub(sub,
    &blkg->delay_nsec);\r\n\t\t\tblkg->last_delay = cur - sub;\r\n\t\t}\r\n\t\tblkg->last_use
    = cur_use;\r\n\t}\r\n}\r\n\r\n/*\r\n * This is called when we want to actually
    walk up the hierarchy and check to\r\n * see if we need to throttle, and then
    actually throttle if there is some\r\n * accumulated delay.  This should only
    be called upon return to user space so\r\n * we're not holding some lock that
    would induce a priority inversion.\r\n */\r\nstatic void blkcg_maybe_throttle_blkg(struct
    blkcg_gq *blkg, bool use_memdelay)\r\n{\r\n\tunsigned long pflags;\r\n\tbool
    clamp;\r\n\tu64 now = ktime_to_ns(ktime_get());\r\n\tu64 exp;\r\n\tu64 delay_nsec
    = 0;\r\n\tint tok;\r\n\r\n\twhile (blkg->parent) {\r\n\t\tint use_delay = atomic_read(&blkg->use_delay);\r\n\r\n\t\tif
    (use_delay) {\r\n\t\t\tu64 this_delay;\r\n\r\n\t\t\tblkcg_scale_delay(blkg, now);\r\n\t\t\tthis_delay
    = atomic64_read(&blkg->delay_nsec);\r\n\t\t\tif (this_delay > delay_nsec) {\r\n\t\t\t\tdelay_nsec
    = this_delay;\r\n\t\t\t\tclamp = use_delay > 0;\r\n\t\t\t}\r\n\t\t}\r\n\t\tblkg
    = blkg->parent;\r\n\t}\r\n\r\n\tif (!delay_nsec)\r\n\t\treturn;\r\n\r\n\t/*\r\n\t
    * Let's not sleep for all eternity if we've amassed a huge delay.\r\n\t * Swapping
    or metadata IO can accumulate 10's of seconds worth of\r\n\t * delay, and we
    want userspace to be able to do _something_ so cap the\r\n\t * delays at 0.25s.
    If there's 10's of seconds worth of delay then the\r\n\t * tasks will be delayed
    for 0.25 second for every syscall. If\r\n\t * blkcg_set_delay() was used as indicated
    by negative use_delay, the\r\n\t * caller is responsible for regulating the range.\r\n\t
    */\r\n\tif (clamp)\r\n\t\tdelay_nsec = min_t(u64, delay_nsec, 250 * NSEC_PER_MSEC);\r\n\r\n\tif
    (use_memdelay)\r\n\t\tpsi_memstall_enter(&pflags);\r\n\r\n\texp = ktime_add_ns(now,
    delay_nsec);\r\n\ttok = io_schedule_prepare();\r\n\tdo {\r\n\t\t__set_current_state(TASK_KILLABLE);\r\n\t\tif
    (!schedule_hrtimeout(&exp, HRTIMER_MODE_ABS))\r\n\t\t\tbreak;\r\n\t} while (!fatal_signal_pending(current));\r\n\tio_schedule_finish(tok);\r\n\r\n\tif
    (use_memdelay)\r\n\t\tpsi_memstall_leave(&pflags);\r\n}\r\n\r\n/**\r\n * blkcg_maybe_throttle_current
    - throttle the current task if it has been marked\r\n *\r\n * This is only called
    if we've been marked with set_notify_resume().  Obviously\r\n * we can be set_notify_resume()
    for reasons other than blkcg throttling, so we\r\n * check to see if current->throttle_queue
    is set and if not this doesn't do\r\n * anything.  This should only ever be called
    by the resume code, it's not meant\r\n * to be called by people willy-nilly as
    it will actually do the work to\r\n * throttle the task if it is setup for throttling.\r\n*/\r\nvoid
    blkcg_maybe_throttle_current(void)\r\n{\r\n\tstruct request_queue *q = current->throttle_queue;\r\n\tstruct
    blkcg *blkcg;\r\n\tstruct blkcg_gq *blkg;\r\n\tbool use_memdelay = current->use_memdelay;\r\n\r\n\tif
    (!q)\r\n\t\treturn;\r\n\r\n\tcurrent->throttle_queue = NULL;\r\n\tcurrent->use_memdelay
    = false;\r\n\r\n\trcu_read_lock();\r\n\tblkcg = css_to_blkcg(blkcg_css());\r\n\tif
    (!blkcg)\r\n\t\tgoto out;\r\n\tblkg = blkg_lookup(blkcg, q);\r\n\tif (!blkg)\r\n\t\tgoto
    out;\r\n\tif (!blkg_tryget(blkg))\r\n\t\tgoto out;\r\n\trcu_read_unlock();\r\n\r\n\tblkcg_maybe_throttle_blkg(blkg,
    use_memdelay);\r\n\tblkg_put(blkg);\r\n\tblk_put_queue(q);\r\n\treturn;\r\nout:\r\n\trcu_read_unlock();\r\n\tblk_put_queue(q);\r\n}\r\n\r\n/**\r\n*
    blkcg_schedule_throttle - this task needs to check for throttling\r\n * @disk:
    disk to throttle\r\n * @use_memdelay: do we charge this to memory delay for PSI\r\n*\r\n*
    This is called by the IO controller when we know there's delay accumulated\r\n*
    for the blkg for this task.  We do not pass the blkg because there are places\r\n*
    we call this that may not have that information, the swapping code for\r\n* instance
    will only have a block_device at that point.  This set's the\r\n * notify_resume
    for the task to check and see if it requires throttling before\r\n* returning
    to user space.\r\n *\r\n * We will only schedule once per syscall.  You can call
    this over and over\r\n * again and it will only do the check once upon return
    to user space, and only\r\n * throttle once.  If the task needs to be throttled
    again it'll need to be\r\n * re-set at the next time we see the task.\r\n */\r\nvoid
    blkcg_schedule_throttle(struct gendisk *disk, bool use_memdelay)\r\n{\r\n\tstruct
    request_queue *q = disk->queue;\r\n\r\n\tif (unlikely(current->flags & PF_KTHREAD))\r\n\t\treturn;\r\n\r\n\tif
    (current->throttle_queue != q) {\r\n\t\tif (!blk_get_queue(q))\r\n\t\t\treturn;\r\n\r\n\t\tif
    (current->throttle_queue)\r\n\t\t\tblk_put_queue(current->throttle_queue);\r\n\t\tcurrent->throttle_queue
    = q;\r\n\t}\r\n\r\n\tif (use_memdelay)\r\n\t\tcurrent->use_memdelay = use_memdelay;\r\n\tset_notify_resume(current);\r\n}\r\n\r\n/**\r\n*
    blkcg_add_delay - add delay to this blkg\r\n * @blkg: blkg of interest\r\n* @now:
    the current time in nanoseconds\r\n * @delta: how many nanoseconds of delay to
    add\r\n *\r\n * Charge @delta to the blkg's current delay accumulation.  This
    is used to\r\n * throttle tasks if an IO controller thinks we need more throttling.\r\n*/\r\nvoid
    blkcg_add_delay(struct blkcg_gq *blkg, u64 now, u64 delta)\r\n{\r\n\tif (WARN_ON_ONCE(atomic_read(&blkg->use_delay)
    < 0))\r\n\t\treturn;\r\n\tblkcg_scale_delay(blkg, now);\r\n\tatomic64_add(delta,
    &blkg->delay_nsec);\r\n}\r\n\r\n/**\r\n * blkg_tryget_closest - try and get a
    blkg ref on the closet blkg\r\n * @bio: target bio\r\n * @css: target css\r\n*\r\n*
    As the failure mode here is to walk up the blkg tree, this ensure that the\r\n*
    blkg->parent pointers are always valid.  This returns the blkg that it ended\r\n*
    up taking a reference on or %NULL if no reference was taken.\r\n*/\r\nstatic
    inline struct blkcg_gq *blkg_tryget_closest(struct bio *bio,\r\n\t\tstruct cgroup_subsys_state
    *css)\r\n{\r\n\tstruct blkcg_gq *blkg, *ret_blkg = NULL;\r\n\r\n\trcu_read_lock();\r\n\tblkg
    = blkg_lookup_create(css_to_blkcg(css), bio->bi_bdev->bd_disk);\r\n\twhile (blkg)
    {\r\n\t\tif (blkg_tryget(blkg)) {\r\n\t\t\tret_blkg = blkg;\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\tblkg
    = blkg->parent;\r\n\t}\r\n\trcu_read_unlock();\r\n\r\n\treturn ret_blkg;\r\n}\r\n\r\n/**\r\n*
    bio_associate_blkg_from_css - associate a bio with a specified css\r\n * @bio:
    target bio\r\n * @css: target css\r\n *\r\n* Associate @bio with the blkg found
    by combining the css's blkg and the\r\n* request_queue of the @bio.  An association
    failure is handled by walking up\r\n* the blkg tree.  Therefore, the blkg associated
    can be anything between @blkg\r\n* and q->root_blkg.  This situation only happens
    when a cgroup is dying and\r\n* then the remaining bios will spill to the closest
    alive blkg.\r\n *\r\n * A reference will be taken on the blkg and will be released
    when @bio is\r\n * freed.\r\n*/\r\nvoid bio_associate_blkg_from_css(struct bio
    *bio,\r\n\t\t\t\t struct cgroup_subsys_state *css)\r\n{\r\n\tif (bio->bi_blkg)\r\n\t\tblkg_put(bio->bi_blkg);\r\n\r\n\tif
    (css && css->parent) {\r\n\t\tbio->bi_blkg = blkg_tryget_closest(bio, css);\r\n\t}
    else {\r\n\t\tblkg_get(bdev_get_queue(bio->bi_bdev)->root_blkg);\r\n\t\tbio->bi_blkg
    = bdev_get_queue(bio->bi_bdev)->root_blkg;\r\n\t}\r\n}\r\nEXPORT_SYMBOL_GPL(bio_associate_blkg_from_css);\r\n\r\n/**\r\n*
    bio_associate_blkg - associate a bio with a blkg\r\n * @bio: target bio\r\n*\r\n*
    Associate @bio with the blkg found from the bio's css and request_queue.\r\n*
    If one is not found, bio_lookup_blkg() creates the blkg.  If a blkg is\r\n* already
    associated, the css is reused and association redone as the\r\n * request_queue
    may have changed.\r\n */\r\nvoid bio_associate_blkg(struct bio *bio)\r\n{\r\n\tstruct
    cgroup_subsys_state *css;\r\n\r\n\trcu_read_lock();\r\n\r\n\tif (bio->bi_blkg)\r\n\t\tcss
    = bio_blkcg_css(bio);\r\n\telse\r\n\t\tcss = blkcg_css();\r\n\r\n\tbio_associate_blkg_from_css(bio,
    css);\r\n\r\n\trcu_read_unlock();\r\n}\r\nEXPORT_SYMBOL_GPL(bio_associate_blkg);\r\n\r\n/**\r\n*
    bio_clone_blkg_association - clone blkg association from src to dst bio\r\n*
    @dst: destination bio\r\n * @src: source bio\r\n */\r\nvoid bio_clone_blkg_association(struct
    bio *dst, struct bio *src)\r\n{\r\n\tif (src->bi_blkg)\r\n\t\tbio_associate_blkg_from_css(dst,
    bio_blkcg_css(src));\r\n}\r\nEXPORT_SYMBOL_GPL(bio_clone_blkg_association);\r\n\r\nstatic
    int blk_cgroup_io_type(struct bio *bio)\r\n{\r\n\tif (op_is_discard(bio->bi_opf))\r\n\t\treturn
    BLKG_IOSTAT_DISCARD;\r\n\tif (op_is_write(bio->bi_opf))\r\n\t\treturn BLKG_IOSTAT_WRITE;\r\n\treturn
    BLKG_IOSTAT_READ;\r\n}\r\n\r\nvoid blk_cgroup_bio_start(struct bio *bio)\r\n{\r\n\tstruct
    blkcg *blkcg = bio->bi_blkg->blkcg;\r\n\tint rwd = blk_cgroup_io_type(bio), cpu;\r\n\tstruct
    blkg_iostat_set *bis;\r\n\tunsigned long flags;\r\n\r\n\tcpu = get_cpu();\r\n\tbis
    = per_cpu_ptr(bio->bi_blkg->iostat_cpu, cpu);\r\n\tflags = u64_stats_update_begin_irqsave(&bis->sync);\r\n\r\n\t/*\r\n\t
    * If the bio is flagged with BIO_CGROUP_ACCT it means this is a split\r\n\t *
    bio and we would have already accounted for the size of the bio.\r\n\t */\r\n\tif
    (!bio_flagged(bio, BIO_CGROUP_ACCT)) {\r\n\t\tbio_set_flag(bio, BIO_CGROUP_ACCT);\r\n\t\tbis->cur.bytes[rwd]
    += bio->bi_iter.bi_size;\r\n\t}\r\n\tbis->cur.ios[rwd]++;\r\n\r\n\t/*\r\n\t *
    If the iostat_cpu isn't in a lockless list, put it into the\r\n\t * list to indicate
    that a stat update is pending.\r\n\t */\r\n\tif (!READ_ONCE(bis->lqueued)) {\r\n\t\tstruct
    llist_head *lhead = this_cpu_ptr(blkcg->lhead);\r\n\r\n\t\tllist_add(&bis->lnode,
    lhead);\r\n\t\tWRITE_ONCE(bis->lqueued, true);\r\n\t\tpercpu_ref_get(&bis->blkg->refcnt);\r\n\t}\r\n\r\n\tu64_stats_update_end_irqrestore(&bis->sync,
    flags);\r\n\tif (cgroup_subsys_on_dfl(io_cgrp_subsys))\r\n\t\tcgroup_rstat_updated(blkcg->css.cgroup,
    cpu);\r\n\tput_cpu();\r\n}\r\n\r\nbool blk_cgroup_congested(void)\r\n{\r\n\tstruct
    cgroup_subsys_state *css;\r\n\tbool ret = false;\r\n\r\n\trcu_read_lock();\r\n\tfor
    (css = blkcg_css(); css; css = css->parent) {\r\n\t\tif (atomic_read(&css->cgroup->congestion_count))
    {\r\n\t\t\tret = true;\r\n\t\t\tbreak;\r\n\t\t}\r\n\t}\r\n\trcu_read_unlock();\r\n\treturn
    ret;\r\n}\r\n\r\nstatic int __init blkcg_init(void)\r\n{\r\n\tblkcg_punt_bio_wq
    = alloc_workqueue(\"blkcg_punt_bio\",\r\n\t\t\t\t\t    WQ_MEM_RECLAIM | WQ_FREEZABLE
    |\r\n\t\t\t\t\t    WQ_UNBOUND | WQ_SYSFS, 0);\r\n\tif (!blkcg_punt_bio_wq)\r\n\t\treturn
    -ENOMEM;\r\n\treturn 0;\r\n}\r\nsubsys_initcall(blkcg_init);\r\n\r\nmodule_param(blkcg_debug_stats,
    bool, 0644);\r\nMODULE_PARM_DESC(blkcg_debug_stats, \"True if you want debug
    stats, false if not\");"
  _textField: {fileID: 1562588492}
  _scrollView: {fileID: 469263117}
  _charPerClick: 2
  _currentText: 
--- !u!1 &519420028
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 519420032}
  - component: {fileID: 519420031}
  - component: {fileID: 519420029}
  - component: {fileID: 519420033}
  m_Layer: 0
  m_Name: Main Camera
  m_TagString: MainCamera
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!81 &519420029
AudioListener:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 519420028}
  m_Enabled: 1
--- !u!20 &519420031
Camera:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 519420028}
  m_Enabled: 1
  serializedVersion: 2
  m_ClearFlags: 2
  m_BackGroundColor: {r: 0.09433961, g: 0.09433961, b: 0.09433961, a: 0}
  m_projectionMatrixMode: 1
  m_GateFitMode: 2
  m_FOVAxisMode: 0
  m_SensorSize: {x: 36, y: 24}
  m_LensShift: {x: 0, y: 0}
  m_FocalLength: 50
  m_NormalizedViewPortRect:
    serializedVersion: 2
    x: 0
    y: 0
    width: 1
    height: 1
  near clip plane: 0.3
  far clip plane: 1000
  field of view: 60
  orthographic: 1
  orthographic size: 5
  m_Depth: -1
  m_CullingMask:
    serializedVersion: 2
    m_Bits: 4294967295
  m_RenderingPath: -1
  m_TargetTexture: {fileID: 0}
  m_TargetDisplay: 0
  m_TargetEye: 0
  m_HDR: 1
  m_AllowMSAA: 0
  m_AllowDynamicResolution: 0
  m_ForceIntoRT: 0
  m_OcclusionCulling: 0
  m_StereoConvergence: 10
  m_StereoSeparation: 0.022
--- !u!4 &519420032
Transform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 519420028}
  m_LocalRotation: {x: 0, y: 0, z: 0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: -10}
  m_LocalScale: {x: 1, y: 1, z: 1}
  m_ConstrainProportionsScale: 0
  m_Children: []
  m_Father: {fileID: 0}
  m_RootOrder: 0
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
--- !u!114 &519420033
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 519420028}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: d7a6d1d86a74dd44faf054a9de092dd4, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
--- !u!1 &770687587
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 770687588}
  - component: {fileID: 770687589}
  m_Layer: 5
  m_Name: Spawner
  m_TagString: Untagged
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!224 &770687588
RectTransform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 770687587}
  m_LocalRotation: {x: -0, y: -0, z: -0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: 0}
  m_LocalScale: {x: 1, y: 1, z: 1}
  m_ConstrainProportionsScale: 0
  m_Children: []
  m_Father: {fileID: 831143112}
  m_RootOrder: 1
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
  m_AnchorMin: {x: 0.5, y: 1}
  m_AnchorMax: {x: 0.5, y: 1}
  m_AnchoredPosition: {x: 0, y: -50}
  m_SizeDelta: {x: 100, y: 100}
  m_Pivot: {x: 0.5, y: 0.5}
--- !u!114 &770687589
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 770687587}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 7edb1b2e169904b4880697b345e8b722, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  _windowPrefab: {fileID: 2788018109049636897, guid: 9a9adf9374f3d914596c13186068af3b, type: 3}
  _spawnDelay: 3
  _startSpawnDelay: 5
--- !u!1 &831143108
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 831143112}
  - component: {fileID: 831143111}
  - component: {fileID: 831143110}
  - component: {fileID: 831143109}
  m_Layer: 5
  m_Name: Canvas
  m_TagString: Untagged
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!114 &831143109
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 831143108}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: dc42784cf147c0c48a680349fa168899, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_IgnoreReversedGraphics: 1
  m_BlockingObjects: 0
  m_BlockingMask:
    serializedVersion: 2
    m_Bits: 4294967295
--- !u!114 &831143110
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 831143108}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 0cd44c1031e13a943bb63640046fad76, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_UiScaleMode: 1
  m_ReferencePixelsPerUnit: 100
  m_ScaleFactor: 1
  m_ReferenceResolution: {x: 1920, y: 1080}
  m_ScreenMatchMode: 0
  m_MatchWidthOrHeight: 0
  m_PhysicalUnit: 3
  m_FallbackScreenDPI: 96
  m_DefaultSpriteDPI: 96
  m_DynamicPixelsPerUnit: 1
  m_PresetInfoIsWorld: 0
--- !u!223 &831143111
Canvas:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 831143108}
  m_Enabled: 1
  serializedVersion: 3
  m_RenderMode: 0
  m_Camera: {fileID: 519420031}
  m_PlaneDistance: 100
  m_PixelPerfect: 0
  m_ReceivesEvents: 1
  m_OverrideSorting: 0
  m_OverridePixelPerfect: 0
  m_SortingBucketNormalizedSize: 0
  m_AdditionalShaderChannelsFlag: 25
  m_SortingLayerID: 0
  m_SortingOrder: 0
  m_TargetDisplay: 0
--- !u!224 &831143112
RectTransform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 831143108}
  m_LocalRotation: {x: 0, y: 0, z: 0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: 0}
  m_LocalScale: {x: 0, y: 0, z: 0}
  m_ConstrainProportionsScale: 0
  m_Children:
  - {fileID: 469263116}
  - {fileID: 770687588}
  m_Father: {fileID: 0}
  m_RootOrder: 1
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
  m_AnchorMin: {x: 0, y: 0}
  m_AnchorMax: {x: 0, y: 0}
  m_AnchoredPosition: {x: 0, y: 0}
  m_SizeDelta: {x: 0, y: 0}
  m_Pivot: {x: 0, y: 0}
--- !u!1 &1298019123
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 1298019126}
  - component: {fileID: 1298019125}
  - component: {fileID: 1298019124}
  m_Layer: 0
  m_Name: EventSystem
  m_TagString: Untagged
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!114 &1298019124
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1298019123}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 4f231c4fb786f3946a6b90b886c48677, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_SendPointerHoverToParent: 1
  m_HorizontalAxis: Horizontal
  m_VerticalAxis: Vertical
  m_SubmitButton: Submit
  m_CancelButton: Cancel
  m_InputActionsPerSecond: 10
  m_RepeatDelay: 0.5
  m_ForceModuleActive: 0
--- !u!114 &1298019125
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1298019123}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 76c392e42b5098c458856cdf6ecaaaa1, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_FirstSelected: {fileID: 0}
  m_sendNavigationEvents: 1
  m_DragThreshold: 10
--- !u!4 &1298019126
Transform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1298019123}
  m_LocalRotation: {x: 0, y: 0, z: 0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: 0}
  m_LocalScale: {x: 1, y: 1, z: 1}
  m_ConstrainProportionsScale: 0
  m_Children: []
  m_Father: {fileID: 0}
  m_RootOrder: 2
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
--- !u!1 &1562588490
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 1562588491}
  - component: {fileID: 1562588494}
  - component: {fileID: 1562588493}
  - component: {fileID: 1562588492}
  m_Layer: 5
  m_Name: Text Field
  m_TagString: Untagged
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!224 &1562588491
RectTransform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1562588490}
  m_LocalRotation: {x: -0, y: -0, z: -0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: 0}
  m_LocalScale: {x: 1, y: 1, z: 1}
  m_ConstrainProportionsScale: 0
  m_Children: []
  m_Father: {fileID: 1700137585}
  m_RootOrder: 0
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
  m_AnchorMin: {x: 0, y: 0}
  m_AnchorMax: {x: 1, y: 1}
  m_AnchoredPosition: {x: 0, y: 0}
  m_SizeDelta: {x: 0, y: 0}
  m_Pivot: {x: 0, y: 1}
--- !u!114 &1562588492
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1562588490}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: f4688fdb7df04437aeb418b961361dc5, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_Material: {fileID: 0}
  m_Color: {r: 1, g: 1, b: 1, a: 1}
  m_RaycastTarget: 0
  m_RaycastPadding: {x: 0, y: 0, z: 0, w: 0}
  m_Maskable: 0
  m_OnCullStateChanged:
    m_PersistentCalls:
      m_Calls: []
  m_text: '|'
  m_isRightToLeft: 0
  m_fontAsset: {fileID: 11400000, guid: 8f586378b4e144a9851e7b34d9b748ee, type: 2}
  m_sharedMaterial: {fileID: 2180264, guid: 8f586378b4e144a9851e7b34d9b748ee, type: 2}
  m_fontSharedMaterials: []
  m_fontMaterial: {fileID: 0}
  m_fontMaterials: []
  m_fontColor32:
    serializedVersion: 2
    rgba: 4283887186
  m_fontColor: {r: 0.3216002, g: 0.9339623, b: 0.33792984, a: 1}
  m_enableVertexGradient: 0
  m_colorMode: 3
  m_fontColorGradient:
    topLeft: {r: 1, g: 1, b: 1, a: 1}
    topRight: {r: 1, g: 1, b: 1, a: 1}
    bottomLeft: {r: 1, g: 1, b: 1, a: 1}
    bottomRight: {r: 1, g: 1, b: 1, a: 1}
  m_fontColorGradientPreset: {fileID: 0}
  m_spriteAsset: {fileID: 0}
  m_tintAllSprites: 0
  m_StyleSheet: {fileID: 0}
  m_TextStyleHashCode: -1183493901
  m_overrideHtmlColors: 0
  m_faceColor:
    serializedVersion: 2
    rgba: 4294967295
  m_fontSize: 20
  m_fontSizeBase: 20
  m_fontWeight: 400
  m_enableAutoSizing: 0
  m_fontSizeMin: 18
  m_fontSizeMax: 72
  m_fontStyle: 0
  m_HorizontalAlignment: 1
  m_VerticalAlignment: 256
  m_textAlignment: 65535
  m_characterSpacing: 0
  m_wordSpacing: 0
  m_lineSpacing: 0
  m_lineSpacingMax: 0
  m_paragraphSpacing: 0
  m_charWidthMaxAdj: 0
  m_enableWordWrapping: 1
  m_wordWrappingRatios: 0.4
  m_overflowMode: 0
  m_linkedTextComponent: {fileID: 0}
  parentLinkedComponent: {fileID: 0}
  m_enableKerning: 1
  m_enableExtraPadding: 0
  checkPaddingRequired: 0
  m_isRichText: 0
  m_parseCtrlCharacters: 1
  m_isOrthographic: 1
  m_isCullingEnabled: 0
  m_horizontalMapping: 0
  m_verticalMapping: 1
  m_uvLineOffset: 0
  m_geometrySortingOrder: 0
  m_IsTextObjectScaleStatic: 0
  m_VertexBufferAutoSizeReduction: 0
  m_useMaxVisibleDescender: 1
  m_pageToDisplay: 1
  m_margin: {x: 0, y: 0, z: 0, w: 0}
  m_isUsingLegacyAnimationComponent: 0
  m_isVolumetricText: 0
  m_hasFontAssetChanged: 0
  m_baseMaterial: {fileID: 0}
  m_maskOffset: {x: 0, y: 0, z: 0, w: 0}
--- !u!222 &1562588493
CanvasRenderer:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1562588490}
  m_CullTransparentMesh: 1
--- !u!114 &1562588494
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1562588490}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 3245ec927659c4140ac4f8d17403cc18, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_HorizontalFit: 0
  m_VerticalFit: 2
--- !u!1 &1700137584
GameObject:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  serializedVersion: 6
  m_Component:
  - component: {fileID: 1700137585}
  - component: {fileID: 1700137588}
  - component: {fileID: 1700137587}
  - component: {fileID: 1700137586}
  m_Layer: 5
  m_Name: View
  m_TagString: Untagged
  m_Icon: {fileID: 0}
  m_NavMeshLayer: 0
  m_StaticEditorFlags: 0
  m_IsActive: 1
--- !u!224 &1700137585
RectTransform:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1700137584}
  m_LocalRotation: {x: -0, y: -0, z: -0, w: 1}
  m_LocalPosition: {x: 0, y: 0, z: 0}
  m_LocalScale: {x: 1, y: 1, z: 1}
  m_ConstrainProportionsScale: 0
  m_Children:
  - {fileID: 1562588491}
  m_Father: {fileID: 469263116}
  m_RootOrder: 0
  m_LocalEulerAnglesHint: {x: 0, y: 0, z: 0}
  m_AnchorMin: {x: 0, y: 0}
  m_AnchorMax: {x: 1, y: 1}
  m_AnchoredPosition: {x: 15, y: -15}
  m_SizeDelta: {x: -30, y: -30}
  m_Pivot: {x: 0, y: 1}
--- !u!114 &1700137586
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1700137584}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 31a19414c41e5ae4aae2af33fee712f6, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_ShowMaskGraphic: 0
--- !u!114 &1700137587
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1700137584}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: fe87c0e1cc204ed48ad3b37840f39efc, type: 3}
  m_Name: 
  m_EditorClassIdentifier: 
  m_Material: {fileID: 0}
  m_Color: {r: 1, g: 1, b: 1, a: 1}
  m_RaycastTarget: 0
  m_RaycastPadding: {x: 0, y: 0, z: 0, w: 0}
  m_Maskable: 0
  m_OnCullStateChanged:
    m_PersistentCalls:
      m_Calls: []
  m_Sprite: {fileID: 10917, guid: 0000000000000000f000000000000000, type: 0}
  m_Type: 1
  m_PreserveAspect: 0
  m_FillCenter: 1
  m_FillMethod: 4
  m_FillAmount: 1
  m_FillClockwise: 1
  m_FillOrigin: 0
  m_UseSpriteMesh: 0
  m_PixelsPerUnitMultiplier: 1
--- !u!222 &1700137588
CanvasRenderer:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 1700137584}
  m_CullTransparentMesh: 1
